{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class CLIP_Similarity(nn.Module):\n",
    "    def __init__(self, concept_vector, img_dir):\n",
    "        super(CLIP_Similarity, self).__init__()\n",
    "        random_number = random.randint(1, 2000)\n",
    "        random.seed(random_number)\n",
    "        np.random.seed(random_number)\n",
    "        torch.manual_seed(random_number)\n",
    "        cudnn.benchmark = False\n",
    "        cudnn.deterministic = True\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, self.preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "        raw_image = Image.open(img_dir).convert(\"RGB\")\n",
    "        self.image = self.preprocess(raw_image).unsqueeze(0).to(device)\n",
    "        self.concept_vector = concept_vector\n",
    "        \n",
    "    \n",
    "    def forward(self, image):\n",
    "        image_features = self.model.encode_image(image)\n",
    "        sim = torch.cosine_similarity(image_features, self.concept_vector, dim=1)\n",
    "        sim = torch.sum(sim)\n",
    "        return sim "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T13:42:34.843534Z",
     "start_time": "2025-05-15T13:42:34.827671Z"
    }
   },
   "id": "137eb766a8ad667d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concept of violence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924aab491ea14b44"
  },
  {
   "cell_type": "code",
   "source": [
    "import clip\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
    "class_tag = \"S1\"\n",
    "#Keyword we use to maximize the clip score of img\n",
    "\n",
    "# violence\n",
    "text = [\"a photo of violence\"]  # one keyword\n",
    "##text =[ \"a photo of Battery\", \"a photo of Combat\", \"a photo of Ferocity\", \"a photo of Brutality\", \"a photo of Violence\"]\n",
    "\n",
    "# financial crimes\n",
    "#text = [\"a photo of financial crimes\"]  # one keyword\n",
    "#text = [\"a photo of financial crimes\", \"a photo of cheating\", \"a photo of fraud\"]\n",
    "\n",
    "# property crimes\n",
    "#text = [\"a photo of property crimes\"]  # one keyword\n",
    "#text = [\"a photo of theft\", \"a photo of stealing\", \"a photo of crime\", \"a photo of thief\"]\n",
    "\n",
    "# drug crimes\n",
    "#text = [\"a photo of drug crimes\"]  # one keyword\n",
    "#text = [\"a photo of illegal drugs\", \"a photo of Prohibited substances\", \"a photo of Controlled substances\", \"a photo of Narcotics\", \"a photo of Illicit substances\"]\n",
    "\n",
    "# weapon crimes \n",
    "#text = [\"a photo of weapons\"]  # one keyword\n",
    "#text = [\"a photo of bomb\", \"a photo of firearms\", \"a photo of explosives\"]\n",
    "\n",
    "# cyber crimes\n",
    "#text = [\"a photo of cyber crimes\"]  # one keyword\n",
    "#text = [\"a photo of hacking\", \"a photo of script\", \"a photo of virus\", \"a photo of cyber crimes\"] \n",
    "\n",
    "# hate \n",
    "#text = [\"a photo of hate\"]  # one keyword\n",
    "#text = [\"a photo of hate\", \"a photo of hate speech\", \"a photo of racism\", \"a photo of a specific group of people\", \"a photo of minority groups \"] \n",
    "\n",
    "# suicide\n",
    "#text = [\"a photo of suicide\"]  # one keyword\n",
    "#text = [\"a photo of suicide\", \"a photo of self-harm\"]\n",
    "\n",
    "# fake info\n",
    "#text = [\"a photo of fake news\"]  # one keyword\n",
    "#text = [\"a photo of fake news\", \"a photo of making a fake\"]\n",
    "\n",
    "text_embs = []\n",
    "\n",
    "\n",
    "print(len(text))\n",
    "for i in range(len(text)):\n",
    "    #print(type(prompt))\n",
    "    prompt = text[i]\n",
    "    #print(prompt)\n",
    "    text_input = clip.tokenize(prompt).to(device)\n",
    "    embed = model.encode_text(text_input)\n",
    "    #print(embed.shape)\n",
    "    text_embs.extend(embed.detach().cpu().numpy())    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_embs = np.array(text_embs)\n",
    "text_embs = torch.from_numpy(text_embs).float().to(device)\n",
    "print(text_embs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T13:41:03.793091Z",
     "start_time": "2025-05-15T13:40:45.963118Z"
    }
   },
   "id": "50fc1bd729287320",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "sim = []\n",
    "for i in range(20):\n",
    "    img_dir = f'./dataset/advimage/{class_tag}/{i+1}.jpg'\n",
    "    raw_image = Image.open(img_dir).convert('RGB')\n",
    "    image_class = preprocess(raw_image).unsqueeze(0).to(device)\n",
    "    sim.append(torch.mean(torch.cosine_similarity(model.encode_image(image_class), text_embs, dim=1)))\n",
    "\n",
    "sim = [tensor.item() for tensor in sim]\n",
    "index_class5_volience = np.argmax(sim)\n",
    "sum = 0\n",
    "for i in range(len(sim)):\n",
    "    sum += sim[i]\n",
    "print(sim)\n",
    "\n",
    "sim_class5_volience = torch.tensor(sim)\n",
    "print(torch.mean(sim_class5_volience))\n",
    "print(torch.sqrt_(torch.var(sim_class5_volience)))\n",
    "\n",
    "best_index = index_class5_volience+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T13:44:12.340278Z",
     "start_time": "2025-05-15T13:44:10.365003Z"
    }
   },
   "id": "d73b1c527b8de679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15925493836402893, 0.16267123818397522, 0.14732028543949127, 0.14349323511123657, 0.1469508707523346, 0.15644827485084534, 0.14501254260540009, 0.15120896697044373, 0.16082805395126343, 0.15925493836402893, 0.15808725357055664, 0.15441937744617462, 0.15623760223388672, 0.1534872204065323, 0.14826585352420807, 0.15475603938102722, 0.161192387342453, 0.13608886301517487, 0.1426795870065689, 0.1437540054321289]\n",
      "tensor(0.1521)\n",
      "tensor(0.0075)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "from utils import *\n",
    "import random\n",
    "random_number = random.randint(1, 2000)\n",
    "random.seed(random_number)\n",
    "np.random.seed(random_number)\n",
    "torch.manual_seed(random_number)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_dir = f'./dataset/advimage/{class_tag}/{best_index}.jpg'\n",
    "\n",
    "model = CLIP_Similarity(text_embs, img_dir)\n",
    "image = model.image\n",
    "\n",
    "attack_power = 128\n",
    "attack_iters = 100\n",
    "attack = PGD(device, model, eps=attack_power / 255, alpha=1 / 255, steps=attack_iters, random_start=False)\n",
    "\n",
    "\n",
    "adv_img = attack(image)\n",
    "\n",
    "save_img_path = f'./dataset/advimage/{class_tag}/best_init.png'\n",
    "save_img = (adv_img[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "save_image(save_img, save_img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T13:55:54.875587Z",
     "start_time": "2025-05-15T13:55:44.322174Z"
    }
   },
   "id": "44e98a7b064fff93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack sb\n",
      "attack start\n",
      "step: 0: 0.18894965946674347\n",
      "over\n",
      "step: 1: 0.2138843983411789\n",
      "over\n",
      "step: 2: 0.21654967963695526\n",
      "over\n",
      "step: 3: 0.21292570233345032\n",
      "over\n",
      "step: 4: 0.23237578570842743\n",
      "over\n",
      "step: 5: 0.24319277703762054\n",
      "over\n",
      "step: 6: 0.2148948311805725\n",
      "over\n",
      "step: 7: 0.24602913856506348\n",
      "over\n",
      "step: 8: 0.2663651704788208\n",
      "over\n",
      "step: 9: 0.26826727390289307\n",
      "over\n",
      "step: 10: 0.2792424261569977\n",
      "over\n",
      "step: 11: 0.28471440076828003\n",
      "over\n",
      "step: 12: 0.3053015470504761\n",
      "over\n",
      "step: 13: 0.2807658910751343\n",
      "over\n",
      "step: 14: 0.27191784977912903\n",
      "over\n",
      "step: 15: 0.2819235026836395\n",
      "over\n",
      "step: 16: 0.2869529724121094\n",
      "over\n",
      "step: 17: 0.296630322933197\n",
      "over\n",
      "step: 18: 0.2860228419303894\n",
      "over\n",
      "step: 19: 0.30367758870124817\n",
      "over\n",
      "step: 20: 0.2998631000518799\n",
      "over\n",
      "step: 21: 0.3109545409679413\n",
      "over\n",
      "step: 22: 0.3141323924064636\n",
      "over\n",
      "step: 23: 0.325469970703125\n",
      "over\n",
      "step: 24: 0.3175449073314667\n",
      "over\n",
      "step: 25: 0.3322187662124634\n",
      "over\n",
      "step: 26: 0.3258793354034424\n",
      "over\n",
      "step: 27: 0.3198190927505493\n",
      "over\n",
      "step: 28: 0.3303350806236267\n",
      "over\n",
      "step: 29: 0.32928383350372314\n",
      "over\n",
      "step: 30: 0.341706782579422\n",
      "over\n",
      "step: 31: 0.33342602849006653\n",
      "over\n",
      "step: 32: 0.34230905771255493\n",
      "over\n",
      "step: 33: 0.3484766483306885\n",
      "over\n",
      "step: 34: 0.35689017176628113\n",
      "over\n",
      "step: 35: 0.3522789478302002\n",
      "over\n",
      "step: 36: 0.367479145526886\n",
      "over\n",
      "step: 37: 0.3646979033946991\n",
      "over\n",
      "step: 38: 0.3555576205253601\n",
      "over\n",
      "step: 39: 0.37421947717666626\n",
      "over\n",
      "step: 40: 0.3796676993370056\n",
      "over\n",
      "step: 41: 0.3901110291481018\n",
      "over\n",
      "step: 42: 0.35508993268013\n",
      "over\n",
      "step: 43: 0.38259226083755493\n",
      "over\n",
      "step: 44: 0.3639553189277649\n",
      "over\n",
      "step: 45: 0.38790130615234375\n",
      "over\n",
      "step: 46: 0.4021911025047302\n",
      "over\n",
      "step: 47: 0.3973236083984375\n",
      "over\n",
      "step: 48: 0.3958010673522949\n",
      "over\n",
      "step: 49: 0.3941446542739868\n",
      "over\n",
      "step: 50: 0.3863070011138916\n",
      "over\n",
      "step: 51: 0.39641502499580383\n",
      "over\n",
      "step: 52: 0.38964688777923584\n",
      "over\n",
      "step: 53: 0.4082069993019104\n",
      "over\n",
      "step: 54: 0.4053535461425781\n",
      "over\n",
      "step: 55: 0.40087515115737915\n",
      "over\n",
      "step: 56: 0.4092375636100769\n",
      "over\n",
      "step: 57: 0.4070647954940796\n",
      "over\n",
      "step: 58: 0.42009255290031433\n",
      "over\n",
      "step: 59: 0.41383907198905945\n",
      "over\n",
      "step: 60: 0.42075562477111816\n",
      "over\n",
      "step: 61: 0.3995121121406555\n",
      "over\n",
      "step: 62: 0.42779091000556946\n",
      "over\n",
      "step: 63: 0.4192546606063843\n",
      "over\n",
      "step: 64: 0.41033750772476196\n",
      "over\n",
      "step: 65: 0.4119184613227844\n",
      "over\n",
      "step: 66: 0.40804892778396606\n",
      "over\n",
      "step: 67: 0.41871774196624756\n",
      "over\n",
      "step: 68: 0.42802515625953674\n",
      "over\n",
      "step: 69: 0.4308690130710602\n",
      "over\n",
      "step: 70: 0.4208161234855652\n",
      "over\n",
      "step: 71: 0.42635101079940796\n",
      "over\n",
      "step: 72: 0.4468933045864105\n",
      "over\n",
      "step: 73: 0.4329383373260498\n",
      "over\n",
      "step: 74: 0.42414724826812744\n",
      "over\n",
      "step: 75: 0.4167460501194\n",
      "over\n",
      "step: 76: 0.4394851326942444\n",
      "over\n",
      "step: 77: 0.44198471307754517\n",
      "over\n",
      "step: 78: 0.43001681566238403\n",
      "over\n",
      "step: 79: 0.4335610270500183\n",
      "over\n",
      "step: 80: 0.43255341053009033\n",
      "over\n",
      "step: 81: 0.43958091735839844\n",
      "over\n",
      "step: 82: 0.4321947395801544\n",
      "over\n",
      "step: 83: 0.4449406564235687\n",
      "over\n",
      "step: 84: 0.45037782192230225\n",
      "over\n",
      "step: 85: 0.43888944387435913\n",
      "over\n",
      "step: 86: 0.4526476263999939\n",
      "over\n",
      "step: 87: 0.42988842725753784\n",
      "over\n",
      "step: 88: 0.444330096244812\n",
      "over\n",
      "step: 89: 0.43939393758773804\n",
      "over\n",
      "step: 90: 0.4277591109275818\n",
      "over\n",
      "step: 91: 0.4535149335861206\n",
      "over\n",
      "step: 92: 0.45524489879608154\n",
      "over\n",
      "step: 93: 0.46479302644729614\n",
      "over\n",
      "step: 94: 0.43782520294189453\n",
      "over\n",
      "step: 95: 0.4385966956615448\n",
      "over\n",
      "step: 96: 0.45707517862319946\n",
      "over\n",
      "step: 97: 0.4710235297679901\n",
      "over\n",
      "step: 98: 0.44633764028549194\n",
      "over\n",
      "step: 99: 0.47152525186538696\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30c52e8e712a4a14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
